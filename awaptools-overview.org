#+TITLE:awaptools 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----
* README-code
#+name:README
#+begin_src R :session *R* :tangle README.md :exports reports :eval no :padline no
  awaptools
  =========
  
  - The Bureau of Meteorology has generated a range of gridded meteorological datasets for Australia as a contribution to the Australian Water Availability Project (AWAP). 
  - An R package to download and format the AWAP grids.
  - Binaries available from [http://swish-climate-impact-assessment.github.com/tools.html](http://swish-climate-impact-assessment.github.com/tools.html)
  - More info is available [http://www.bom.gov.au/jsp/awap/](http://www.bom.gov.au/jsp/awap/)
  - The documentation of the data creation is at [http://www.bom.gov.au/amm/docs/2009/jones.pdf](http://www.bom.gov.au/amm/docs/2009/jones.pdf)
  
  #### R-Code: A workflow to download and process the public BoM weather grids.
  
  ```r
  # depends
  install.packages(c('raster', 'rgdal', 'plyr', 'RODBC', 'RCurl', 'XML', 'ggmap', 'maptools', 'spdep'))
  
  # This workflow uses the open source R software with some of our custom written packages:
  # aim daily weather for any point location from online BoM weather grids
  # depends on some github packages, either use devtools
  install.packages("devtools")
  library(devtools)
  install_github("awaptools", "swish-climate-impact-assessment")
  install_github("swishdbtools", "swish-climate-impact-assessment")
  install_github("gisviz", "ivanhanigan")
  
  # OR download and install
  # http://swish-climate-impact-assessment.github.io/tools/awaptools/awaptools-downloads.html
  # http://swish-climate-impact-assessment.github.io/tools/swishdbtools/swishdbtools-downloads.html
  # http://ivanhanigan.github.io/gisviz/
  
  library(awaptools)
  library(swishdbtools)
  library(gisviz)   
  library(reshape) 
  # get weather data, beware that each grid is a couple of megabytes
  vars <- c("maxave","minave","totals","vprph09","vprph15") #,"solarave") 
  # solar only available after 1990
  for(measure in vars)
  {
    #measure <- vars[1]
    get_awap_data(start = '2016-03-04',end = '2016-03-06', measure)
  }
   
  # get location
  address2 <- c("1 Lineaus way acton canberra", "daintree forest queensland", "hobart",
                "bourke")
  locn <- gGeoCode2(address2, first = T)
  
  # this uses google maps API, better check this
  locn
  
  ## Treat data frame as spatial points
  epsg <- make_EPSG()
  shp <- SpatialPointsDataFrame(cbind(locn$lon,locn$lat),locn,
                                proj4string=CRS(epsg$prj4[epsg$code %in% '4283']))
  # now loop over grids and extract met data
  cfiles <-  dir(pattern="grid$")
   
  for (i in seq_len(length(cfiles))) {
    #i <- 1 ## for stepping thru
    gridname <- cfiles[[i]]
    r <- raster(gridname)
    #image(r) # plot to look at
    e <- extract(r, shp, df=T)
    #str(e) ## print for debugging
    e1 <- shp
    e1@data$values <- e[,2]
    e1@data$gridname <- gridname
    # write to to target file
    write.table(e1@data,"output.csv",
      col.names = i == 1, append = i>1 , sep = ",", row.names = FALSE)
  }
  # further work is required to format the column with the gridname to get out the date and weather paramaters.
  
  dat <- read.csv("output.csv", stringsAsFactors = F)
  head(dat)
  dat$date <- matrix(unlist(strsplit(dat$gridname, "_")), ncol = 2, byrow=TRUE)[,2]
  dat$date <- paste(substr(dat$date,1,4), substr(dat$date,5,6), substr(dat$date,7,8), sep = "-")
  dat$measure <- matrix(unlist(strsplit(dat$gridname, "_")), ncol = 2, byrow=TRUE)[,1]
  
  
  dat <- arrange(dat[,c("address", "long", "lat", "date", "measure", "values")], address, date, measure)
  head(dat)
  
  dat2 <- cast(dat, address +    long     +  lat    +   date ~ measure, value = 'values',
        fun.aggregate= 'mean')
  dat2
  
  "
                          address     long       lat       date maxave minave
  1  1 Lineaus way acton canberra 149.1164 -35.27676 2016-03-04  32.55  15.10
  2  1 Lineaus way acton canberra 149.1164 -35.27676 2016-03-05  35.04  15.24
  3  1 Lineaus way acton canberra 149.1164 -35.27676 2016-03-06  34.09  15.36
  4                        bourke 145.9375 -30.09011 2016-03-04  39.01  25.97
  5                        bourke 145.9375 -30.09011 2016-03-05  38.89  22.15
  6                        bourke 145.9375 -30.09011 2016-03-06  38.36  21.83
  7    daintree forest queensland 145.3798 -16.24014 2016-03-04  28.53  23.70
  8    daintree forest queensland 145.3798 -16.24014 2016-03-05  29.09  24.51
  9    daintree forest queensland 145.3798 -16.24014 2016-03-06  31.28  24.86
  10                       hobart 147.3238 -42.88190 2016-03-04  24.20  12.85
  11                       hobart 147.3238 -42.88190 2016-03-05  24.89  12.36
  12                       hobart 147.3238 -42.88190 2016-03-06  22.88  14.22
     totals vprph09 vprph15
  1     8.1   17.49   13.92
  2     0.1   16.28   13.18
  3     1.3   16.25    7.74
  4     0.1   14.09   12.43
  5     0.0   15.94   12.02
  6     0.0   12.80   11.31
  7    90.8   31.10   29.32
  8    44.3   29.84   30.60
  9    18.8   31.75   30.40
  10    0.0   14.23   14.45
  11    0.0   12.84   12.62
  12    0.3   14.94   13.90
  "
  
  png(sprintf("%s-test.png", gridname))
  plot(r)
  plot(shp, add = T)
  title(gridname)
  dev.off()
  
  ```
  
  ![tests/vprph15_2016030620160306.grid-test.png](tests/vprph15_2016030620160306.grid-test.png)
  
  
  ```r
  # most data are available since 1950
  vars <- c("maxave","minave","totals","vprph09","vprph15") #,"solarave") 
  # solar only available after 1990
  for(measure in vars)
  {
    #measure <- vars[1]
    get_awap_data(start = '1950-01-01',end = '1950-01-01', measure)
  }
  
  # rainfall since 1900
  measure <- "totals"
  get_awap_data(start = '1900-01-01',end = '1900-01-01', measure)
  
  #...
  "
                          address     long       lat       date maxave minave
  1  1 Lineaus way acton canberra 149.1164 -35.27676 1900-01-01    NaN    NaN
  2  1 Lineaus way acton canberra 149.1164 -35.27676 1949-01-01  20.95  10.10
  3  1 Lineaus way acton canberra 149.1164 -35.27676 1950-01-01  23.31  14.26
  4  1 Lineaus way acton canberra 149.1164 -35.27676 2016-03-04  32.55  15.10
  5  1 Lineaus way acton canberra 149.1164 -35.27676 2016-03-05  35.04  15.24
  6  1 Lineaus way acton canberra 149.1164 -35.27676 2016-03-06  34.09  15.36
  7                        bourke 145.9375 -30.09011 1900-01-01    NaN    NaN
  8                        bourke 145.9375 -30.09011 1949-01-01  31.22  13.95
  9                        bourke 145.9375 -30.09011 1950-01-01  40.13  26.74
  10                       bourke 145.9375 -30.09011 2016-03-04  39.01  25.97
  11                       bourke 145.9375 -30.09011 2016-03-05  38.89  22.15
  12                       bourke 145.9375 -30.09011 2016-03-06  38.36  21.83
  13   daintree forest queensland 145.3798 -16.24014 1900-01-01    NaN    NaN
  14   daintree forest queensland 145.3798 -16.24014 1949-01-01  32.30  25.32
  15   daintree forest queensland 145.3798 -16.24014 1950-01-01  32.43  23.26
  16   daintree forest queensland 145.3798 -16.24014 2016-03-04  28.53  23.70
  17   daintree forest queensland 145.3798 -16.24014 2016-03-05  29.09  24.51
  18   daintree forest queensland 145.3798 -16.24014 2016-03-06  31.28  24.86
  19                       hobart 147.3238 -42.88190 1900-01-01    NaN    NaN
  20                       hobart 147.3238 -42.88190 1949-01-01  14.28   8.87
  21                       hobart 147.3238 -42.88190 1950-01-01  23.77   5.75
  22                       hobart 147.3238 -42.88190 2016-03-04  24.20  12.85
  23                       hobart 147.3238 -42.88190 2016-03-05  24.89  12.36
  24                       hobart 147.3238 -42.88190 2016-03-06  22.88  14.22
     totals vprph09 vprph15
  1     0.0     NaN     NaN
  2    10.3     NaN     NaN
  3     0.0   12.42   12.19
  4     8.1   17.49   13.92
  5     0.1   16.28   13.18
  6     1.3   16.25    7.74
  7     0.3     NaN     NaN
  8     0.0     NaN     NaN
  9     0.1   18.77   13.88
  10    0.1   14.09   12.43
  11    0.0   15.94   12.02
  12    0.0   12.80   11.31
  13    3.0     NaN     NaN
  14    1.7     NaN     NaN
  15    0.7   22.73   20.11
  16   90.8   31.10   29.32
  17   44.3   29.84   30.60
  18   18.8   31.75   30.40
  19    0.0     NaN     NaN
  20    1.2     NaN     NaN
  21    0.3    7.52    7.47
  22    0.0   14.23   14.45
  23    0.0   12.84   12.62
  24    0.3   14.94   13.90
  "
  
  ```
#+end_src

*  PACKAGE 
** get_awap_data
*** R-get_awap_data
#+name:get_awap_data
#+begin_src R :session *R* :tangle R/get_awap_data.r :exports none :eval no
################################################################
# name:get_awap_data
get_awap_data <- function(start, end, measure_i)
{
  variableslist <- variableslist()  
  variable <- variableslist[which(variableslist$measure == measure_i),]
  vname <- as.character(variable[,1])
  datelist <- seq(as.Date(start), as.Date(end), 1)
  
  for(date_i in datelist)
  {
    # date_i <- datelist[1]
    date_i <- as.Date(date_i, origin = '1970-01-01')
    sdate <- as.character(date_i)
    edate <- date_i
    
    if(!file.exists(sprintf("%s_%s%s.grid",measure_i,gsub("-","",sdate),gsub("-","",edate))))
    {
      get_data_range(variable=as.character(variable[,1]),
                     measure=as.character(variable[,2]),
                     timestep=as.character(variable[,3]),
                     startdate=as.POSIXct(sdate),
                     enddate=as.POSIXct(edate))
      
      fname <- sprintf("%s_%s%s.grid.Z",measure_i,gsub("-","",sdate),gsub("-","",edate))
      if(file.info(fname)$size == 0)
      {
        file.remove(fname)
        next
      }
      os <- LinuxOperatingSystem()
      if(os)
      {
        uncompress_linux(filename = fname)
      } else {
        Decompress7Zip(zipFileName= fname, outputDirectory=getwd(), TRUE)
      }
    }
  }
  
}

#+end_src
*** test-get_awap_data
#+name:get_awap_data
#+begin_src R :session *R* :tangle tests/test-get_awap_data.r :exports none :eval no
################################################################
# name:get_awap_data
# test

# functions
require(devtools)
install_github('awaptools','swish-climate-impact-assessment')
require(awaptools)
install_github('swishdbtools','swish-climate-impact-assessment')
require(swishdbtools)
variableslist <- variableslist()  
vars <- c("maxave","minave","totals","vprph09","vprph15","solarave")
for(measure in vars)
{
  get_awap_data(start = '1990-01-01',end = '1990-01-01', measure)
}
fileslist <- dir(pattern="grid$")
r <- readGDAL(fname=fileslist[5])
image(r)
#+end_src
*** man-get_awap_data
#+name:get_awap_data
#+begin_src markdown :tangle man/get_awap_data.Rd :exports none :eval no :padline no
\name{get_awap_data}
\alias{get_awap_data}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{
Get AWAP data
}
\description{
Download grids from BoM site
}
\usage{
get_awap_data(start, end, measure_i)
}
%- maybe also 'usage' for other objects documented here.
\arguments{
  \item{start}{
start date for downloading from
}
  \item{end}{
end date for downloading from
}
  \item{measure_i}{
meteorological variable to download.  see variableslist() 
}

}
\details{
Makes assumptions:
linux has gzip and windoze has 7zip in default locations

please download swish R packages from 
 http://swish-climate-impact-assessment.github.io/tools/swishdbtools/swishdbtools-downloads.html

http://swish-climate-impact-assessment.github.io/tools/awaptools/awaptools-downloads.html

}
\value{
The downloaded files will be unzipped (depends on zip software) into the current working directory
%%  ~Describe the value returned
%%  If it is a LIST, use
%%  \item{comp1 }{Description of 'comp1'}
%%  \item{comp2 }{Description of 'comp2'}
%% ...
}
\references{
%% ~put references to the literature/web site here ~
}
\author{
ivanhanigan
}
\note{
%%  ~~further notes~~
}

%% ~Make other sections like Warning with \section{Warning }{....} ~

\seealso{
%% ~~objects to See Also as \code{\link{help}}, ~~~
}
\examples{
## Not run:
require(awaptools)
require(swishdbtools)
variableslist <- variableslist()  
vars <- c("maxave","minave","totals","vprph09","vprph15","solarave")
for(measure in vars)
{
  get_awap_data(start = '1990-01-01',end = '1990-01-01', measure)
}
fileslist <- dir(pattern="grid$")
r <- readGDAL(fname=fileslist[1])
image(r)

## End(Not run)
}
% Add one or more standard keywords, see file 'KEYWORDS' in the
% R documentation directory.
\keyword{ ~kwd1 }
\keyword{ ~kwd2 }% __ONLY ONE__ keyword per line

#+end_src

** core libs
#+begin_src R  :session *R* :exports none :eval no :tangle R/func.r
  # Project: AWAP_GRIDS
  # Author: ivanhanigan
  # Maintainer: Who to complain to <ivan.hanigan@gmail.com>
  
  # Functions for the project
  if (!require(plyr)) install.packages('plyr', repos='http://cran.csiro.au'); require(plyr)
  if(!require(swishdbtools)){
  if(length(grep('linux',sessionInfo()[[1]]$os)) == 1)
  {
    os <- 'linux'
  
  print('Downloading the swishdbtools package and install it.')
   download.file('http://swish-climate-impact-assessment.github.com/tools/swishdbtools/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz', '~/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz', mode = 'wb')
  # for instance
  install.packages("~/swishdbtools_1.1_R_x86_64-pc-linux-gnu.tar.gz", repos = NULL, type = "source");
  
  } else {
      os <- 'windows'
  
  print('Downloading the swishdbtools package and install it.')
   download.file('http://swish-climate-impact-assessment.github.com/tools/swishdbtools/swishdbtools_1.1.zip', '~/swishdbtools_1.1.zip', mode = 'wb')
  # for instance
  install.packages("~/swishdbtools_1.1.zip", repos = NULL);
  
  }
  }
  require(swishdbtools)
  if(!require(raster)) install.packages('raster', repos='http://cran.csiro.au');require(raster)
  if(!require(fgui)) install.packages('fgui', repos='http://cran.csiro.au');require(fgui)
  if(!require(rgdal)) install.packages('rgdal', repos='http://cran.csiro.au');require(rgdal)
  
  ####
  # MAKE SURE YOU HAVE THE CORE LIBS
  if (!require(lubridate)) install.packages('lubridate', repos='http://cran.csiro.au'); require(lubridate)
  if (!require(reshape)) install.packages('reshape', repos='http://cran.csiro.au'); require(reshape)
  if (!require(plyr)) install.packages('plyr', repos='http://cran.csiro.au'); require(plyr)
  if (!require(ggplot2)) install.packages('ggplot2', repos='http://cran.csiro.au'); require(ggplot2)
  
#+end_src
** check_duplicates-lib
#+name:check_duplicates
#+begin_src R :session *R* :tangle R/check_duplicates.r :exports none :eval no
  ################################################################
  # name:check_duplicates
  check_duplicates <- function(conn, measures = c("vprph09","vprph15"), measure_name = "vprph", dates)
    {
    #suspicious_dates <- list()
    #measures <- c("maxave","minave", "solarave","totals",
  
    for(j in 1:length(dates))
      {
        #date_j <- dates[2]
        date_j <- dates[j]
        date_i <- gsub("-","",date_j)
        print(date_i)
        rasters <- list()
  
    #      print(measure)
          rastername1 <- paste(measures[1], "_", date_i, sep ="")
          rastername2 <- paste(measures[2], "_", date_i, sep ="")
          tableExists <- pgListTables(ch, schema="awap_grids",
      table=rastername1, match = TRUE)
          tableExists2 <- pgListTables(ch, schema="awap_grids", table=rastername2, match = TRUE)
          if(nrow(tableExists) == 0 | nrow(tableExists2) == 0)
          {
            next
          }
        for(i in 1:length(measures))
        {
    #      i = 2
          measure <- measures[i]
          rastername <- paste(measures[i], "_", date_i, sep ="")
            r1 <- readGDAL2("115.146.84.135", "gislibrary", "ewedb",
                            "awap_grids", rastername, p = pwd)
    #        image(r1)
            rasters[[i]] <- r1
  
        }
          ## str(rasters)
        ##   par(mfrow = c(1,2))
        ##   image(rasters[[1]])
        ##   image(rasters[[2]])
        suspect <- identical(rasters[[1]]@data, rasters[[2]]@data)
        #all.equal(head(rasters[[1]]@data), head(rasters[[2]]@data))
        if(suspect)
          {
            #counter <- length(suspicious_dates)
            #suspicious_dates[[counter + 1]] <- rastername
            sink(paste("sus_dates_",measure_name,".csv", sep = ""), append = T)
            cat(rastername)
            cat('\n')
            sink()
          }
        rm(suspect)
  
      }
  
    #return(suspicious_dates)
    }
  
#+end_src

** DatesUnavaliable
*** COMMENT test-DatesUnavailable
#+name:DatesUnavailable
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:DatesUnavailable
  require(devtools)
  install_github("awaptools", "swish-climate-impact-assessment")
  DatesUnavailable
  
#+end_src
*** COMMENT R-DatesUnavailable
#+name:DatesUnavailable
#+begin_src R :session *shell* :tangle R/DatesUnavailable.R :exports none :eval no
###########################################################################
# newnode: DatesUnavailable

# get the list of dates between the start and end dates that is not found in the database 
DatesUnavailable <- function (dataBaseConnection, variableName, startDate, endDate) 
{
  ch <- dataBaseConnection
  measure_i <- variableName
  start_at <- startDate
  end_at <- endDate
  
  datelist_full <- as.data.frame(seq(as.Date(start_at),
                                     as.Date(end_at), 1))
  names(datelist_full) <- 'date'
  
  
  tbls <- pgListTables(conn=ch, schema='awap_grids', table = measure_i, match = FALSE)
  #     pattern=paste(measure_i,"_", gsub("-","",sdate), sep=""))
  pattern_x <- paste(measure_i,"_",sep="")
  tbls$date <- paste(
    substr(gsub(pattern_x,"",tbls[,1]),1,4),
    substr(gsub(pattern_x,"",tbls[,1]),5,6),
    substr(gsub(pattern_x,"",tbls[,1]),7,8),
    sep="-")
  tbls$date <- as.Date(tbls$date)
  datelist <-  which(datelist_full$date %in% tbls$date)
  
  
  if(length(datelist) == 0)
  {
    datelist <- datelist_full[,]
  } else {
    datelist <- datelist_full[-datelist,]
  }
  
  
}


#+end_src

** Get Data 
#+begin_src R :session *R* :tangle R/get_data.r :exports none :eval no
# newnode get_data
# authors: Joseph Guillaume
# downloads from http://www.bom.gov.au/jsp/awap/
get_data<-function(variable,measure,timestep,startdate,enddate){
  url="http://www.bom.gov.au/web03/ncc/www/awap/{variable}/{measure}/{timestep}/grid/0.05/history/nat/{startdate}{enddate}.grid.Z"
  url=gsub("{variable}",variable,url,fixed=TRUE)
  url=gsub("{measure}",measure,url,fixed=TRUE)
  url=gsub("{timestep}",timestep,url,fixed=TRUE)
  url=gsub("{startdate}",startdate,url,fixed=TRUE)
  url=gsub("{enddate}",enddate,url,fixed=TRUE)

  try(download.file(url,sprintf("%s_%s%s.grid.Z",measure,startdate,enddate),mode="wb"))
  }
#+end_src
** Get Data Range
*** COMMENT test-get_data_range-code
#+name:test-get_data_range
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:test-get_data_range
  require(awaptools)
  variableslist <- variableslist()
  variableslist
  get_data_range(
                 variable = variableslist[1,1]
                 ,
                 measure = variableslist[1,2]
                 ,
                 timestep = "monthly"
                 ,
                 startdate = as.POSIXct("1911-01-01")
                 ,
                 enddate = as.POSIXct("1911-06-01")
                 )
  
#+end_src
*** get_data_range-code
#+begin_src R :session *R* :tangle R/get_data_range.r :exports none :eval no
  # newnode get_data_range
  # authors: Joseph Guillaume and Francis Markham
  # downloads from http://www.bom.gov.au/jsp/awap/
  
  get_data_range<-function(variable,measure,timestep,startdate,enddate){
    if (timestep == "daily"){
      thisdate<-startdate
      while (thisdate<=enddate){
        get_data(variable,measure,timestep,format(as.POSIXct(thisdate),"%Y%m%d"),format(as.POSIXct(thisdate),"%Y%m%d"))
        thisdate<-thisdate+as.double(as.difftime(1,units="days"),units="secs")
      }
    } else if (timestep == "month" | timestep == "monthly"){
      timestep <- "month"
      # Make sure that we go from begin of the month
      startdate <- as.POSIXlt(startdate)
      startdate$mday <- 1
      # Find the first and last day of each month overlapping our range
      data.period.start <- seq(as.Date(startdate), as.Date(enddate), by = 'month')
      data.period.end <- as.Date(sapply(data.period.start, FUN=function(x){as.character(seq(x, x + 40, by = 'month')[2] - 1)}))
      # Download them
      for (i in 1:length(data.period.start))
        {
          # i <- 1
          get_data(variable,measure,timestep,
                   format(as.POSIXct(data.period.start[i]),"%Y%m%d"),
                   format(as.POSIXct(data.period.end[i]),"%Y%m%d")
                   )
        }
  
  } else {
      stop("Unsupported timestep, only 'daily' and 'month' are currently supported")
    }
  }
  
#+end_src

** variableslist
#+name:variableslist
#+begin_src R :session *R* :tangle R/variableslist.r :exports none :eval no
  #####################################################################
  # newnode: variableslist
  variableslist <- function()
    {
    variablesList<-"variable,measure,timestep
  rainfall,totals,daily
  temperature,maxave,daily
  temperature,minave,daily
  vprp,vprph09,daily
  vprp,vprph15,daily
  solar,solarave,daily
  ndvi,ndviave,month"
    variablesList <- read.csv(textConnection(variablesList), stringsAsFactors = F)
    return(variablesList)
    }
  
#+end_src

** ProcessFunctions
#+name:ProcessFunctions.R
#+begin_src R :session *R* :tangle R/ProcessFunctions.R :exports none :eval no
  ################################################################
  # name:ProcessFunctions.R
  
  RunProcess = function(executable, arguments)
  {
    command = paste(sep="", "\"", executable,  "\" ", arguments);
    
    print (command)
    
    exitCode = system(command, intern = FALSE, ignore.stdout = FALSE, ignore.stderr = FALSE, wait = TRUE, input = NULL
                      , show.output.on.console = TRUE
                      #, minimized = FALSE
                      , invisible = FALSE
    );
    if(exitCode != 0)
    {
      stop("Process returned error");
    }
    return (exitCode)
  }
  
  
  RunViaBat = function(executableFileName, arguments)
  {
    command = paste(sep="", "\"", executableFileName,  "\" ", arguments);
    sink("C:\\Users\\u5265691\\Desktop\\ThingToRun.bat")
    cat(command)
    sink()
    
    exitCode = system("C:\\Users\\u5265691\\Desktop\\ThingToRun.bat")
    if(exitCode != 0)
    {
      stop("Process returned error");
    }
    return (exitCode)
  }
  
#+end_src

** ZipFunctions
#+name:ZipFunctions.R
#+begin_src R :session *R* :tangle R/ZipFunctions.R :exports none :eval no
  ################################################################
  # name:ZipFunctions.R
  uncompress_linux <- function(filename)
    {
      print(filename)
      system(sprintf('uncompress %s',filename))
    }
  
  # tries to find 7 zip exe
  ExecutableFileName7Zip <- function()
  {
    executableName <- "C:\\Program Files\\7-Zip\\7z.exe"
  
    if(file.exists(executableName))
    {
      return (executableName)
    }
  
    #other executable file names and ideas go here ...
    stop("failed to find 7zip")
  }
  
  # simple function to extract 7zip file
  # need to have 7zip installed
  Decompress7Zip <- function(zipFileName, outputDirectory, delete)
  {
    executableName <- ExecutableFileName7Zip()
  
  #   fileName = GetFileName(zipFileName)
  #   fileName = PathCombine(outputDirectory, fileName)
  
  
  #   if(file.exists(fileName))
  #   {
  #     unlink(zipFileName);
  #   }
  
    arguments <- paste(sep="",
                      "e ",
                      "\"", zipFileName, "\" ",
                      "\"-o", outputDirectory, "\" ",
      "")
  
    print( arguments)
  
    RunProcess(executableName, arguments)
  
    if(delete)
    {
      unlink(zipFileName);
    }
  }
  
  #test
  # Decompress7Zip("D:\\Development\\Awap Work\\2013010820130108.grid.Z", "D:\\Development\\Awap Work\\", TRUE)
  
#+end_src

** raster_aggregate
#+name:raster_aggregate
#+begin_src R :session *R* :tangle R/raster_aggregate.r :exports none :eval no
  ################################################################
  # name:raster_aggregate
  raster_aggregate <- function(filename, aggregationfactor, delete = TRUE, fname = filename)
  {
    r <- raster(filename)
    if(aggregationfactor > 1) r <- aggregate(r, fact = aggregationfactor, fun = mean)
    writeRaster(r, gsub('.grid','',fname), format="GTiff",
  overwrite = TRUE)
    if(delete)
      {
        file.remove(filename)
      }
  }
  
#+end_src

** COMMENT load2postgres_raster
#+name:load2postgres_raster
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:load2postgres_raster
  load2postgres_raster <- function(filename, remove = TRUE)
  {
    outname <- gsub('.tif',"", filename)
    outname <- substr(outname, 1, nchar(outname) - 8)
    if(os == 'linux')
    {
     system(
    #        cat(
            paste(pgisutils,"raster2pgsql -s 4283 -I -C -M ",filename," -F awap_grids.",outname," > ",outname,".sql", sep="")
            )
  
     system(
    #        cat(
            paste("psql -h 115.146.84.135 -U gislibrary -d ewedb -f ",outname,".sql",
              sep = ""))
    } else {
      sink('raster2sql.bat')
      cat(paste(pgisutils,"raster2pgsql\" -s 4283 -I -C -M ",filename," -F awap_grids.",outname," > ",outname,".sql\n",sep=""))
  
      cat(
      paste(pgutils,"psql\" -h 115.146.84.135 -U gislibrary -d ewedb -f ",outname,".sql",
      sep = "")
        )
      sink()
      system('raster2sql.bat')
      file.remove('raster2sql.bat')
    }
  
    if(remove)
      {
        file.remove(filename)
        file.remove(paste(outname, '.sql', sep =""))
      }
  }
  
#+end_src

** COMMENT deprecated pgListTables, moved to swishdbtools
#+name:pgListTables
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:pgListTables
  pgListTables <- function(conn, schema, pattern = NA)
  {
    tables <- dbGetQuery(conn, 'select   c.relname, nspname
                         FROM pg_catalog.pg_class c
                         LEFT JOIN pg_catalog.pg_namespace n
                         ON n.oid = c.relnamespace
                         where c.relkind IN (\'r\',\'\') ')
    tables <- tables[grep(schema,tables$nspname),]
    if(!is.na(pattern)) tables <- tables[grep(pattern, tables$relname),]
    tables <- tables[order(tables$relname),]
    return(tables)
  }
#+end_src
** COMMENT pgListTables
#+name:pgListTables
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:pgListTables
pgListTables <- function(conn, schema, pattern = NA)
{
  tables <- dbGetQuery(conn, "select   c.relname, nspname
                       FROM pg_catalog.pg_class c
                       LEFT JOIN pg_catalog.pg_namespace n
                       ON n.oid = c.relnamespace
                       where c.relkind IN ('r','','v') ")
  tables <- tables[grep(schema,tables$nspname),]
  if(!is.na(pattern)) tables <- tables[grep(pattern, tables$relname),]
  tables <- tables[order(tables$relname),]
  return(tables)
}
#+end_src

** COMMENT pgListTables-test dates
#+name:pgListTables-test
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:pgListTables-test
  require(ProjectTemplate)
  load.project()
  
  require(swishdbtools)
  p <- getPassword(remote=T)
  ch <- connect2postgres(h = '115.146.84.135', db = 'ewedb', user=
                         'gislibrary', p=p)
  measure_i <- 'vprph15'
  tbls <- pgListTables(conn=ch, schema='awap_grids', table=measure_i, match = FALSE)
  tbls$date <- paste(substr(gsub(paste(measure_i,"_",sep=""),"",tbls[,1]),1,4),
          substr(gsub(paste(measure_i,"_",sep=""),"",tbls[,1]),5,6),
          substr(gsub(paste(measure_i,"_",sep=""),"",tbls[,1]),7,8),
          sep="-")
  tbls$date <- as.Date(tbls$date)
  head(tbls)
  tbls <- tbls[tbls$date > as.Date('1912-01-01'),]
  plot(tbls$date, rep(1,nrow(tbls)), type = 'h')
  tbls[tbls$date < as.Date('1999-01-01'),]
  tbls[tbls$date >= as.Date('2006-07-01') & tbls$date < as.Date('2007-01-01'),]
  tbls[tbls$date >= as.Date('2004-01-01') & tbls$date < as.Date('2005-01-01'),]
  
#+end_src
** sqlquery_oracle
#+name:sqlquery
#+begin_src R :session *R* :tangle R/sqlquery.r :exports none :eval no
  ################################################################
  # name:aggregate_postgres
  sqlquery <- function(channel, dimensions, operation,
                       variable, variablename=NA, into, append = FALSE,
                       tablename, where, group_by_dimensions=NA,
                       having=NA,
                       grant = NA, force = FALSE,
                       print = FALSE)
  {
  
    exists <- try(dbGetQuery(channel,
                             paste("select * from",into,"limit 1")))
    if(!force & length(exists) > 0 & append == FALSE)
                             stop("Table exists. Force Drop or Insert Into?")
    if(force & length(exists) > 0) dbGetQuery(channel,
                             paste("drop table ",into))
    if(length(exists) > 0 & append == TRUE)
      {
        sqlquery <- paste("INSERT INTO ",into," (",
                             paste(names(exists), collapse=',', sep='') ,")\n",
                          "select ", dimensions,
                          sep = ""
                          )
      } else {
        sqlquery <- paste("select ", dimensions, sep = "")
      }
    if(!is.na(operation))
    {
    sqlquery <- paste(sqlquery, ", ", operation, "(",variable,") as ",
      ifelse(is.na(variablename), variable,
      variablename), '\n', sep = "")
    }
    if(append == FALSE){
      sqlquery <- paste(sqlquery, "into ", into ,"\n", sep = "")
    }
    sqlquery <- paste(sqlquery, "from ", tablename ,"\n", sep = "")
    if(!is.na(where))
    {
    sqlquery <- paste(sqlquery, "where ", where, "\n", sep = "")
    }
    if(group_by_dimensions == TRUE)
    {
    sqlquery <- paste(sqlquery, "group by ",dimensions, "\n", sep = "")
    }
  #  cat(sqlquery)
  
  
  
    ## sqlquery <-  paste("select ", dimensions,
    ##                ", ",operation,"(",variables,") as ",variables,
    ##                operation, "
    ##                into ", into ,"
    ##                from ",tablename," t1
    ##                group by ",dimensions,
    ##                sep="")
    if(print) {
      cat(sqlquery)
    } else {
      dbSendQuery(channel, sqlquery)
    }
  
  }
#+end_src
** sqlquery_postgres
#+name:sqlquery
#+begin_src R :session *R* :tangle R/sqlquery_postgres.r :exports none :eval no
  ################################################################
  # name:aggregate_postgres
    
  sqlquery_postgres <- function(channel, dimensions, operation,
                       variable, variablename=NA, into_schema = 'public',
                       into_table, append = FALSE,
                       from_schema = 'public', from_table, where=NA,
                       group_by_dimensions=NA,
                       having=NA,
                       grant = NA, force = FALSE,
                       print = FALSE)
  {
    # assume ch exists
    exists <- pgListTables(channel, into_schema, into_table)
    if(!force & nrow(exists) > 0 & append == FALSE)
      {
        stop("Table exists. Force Drop or Insert Into?")
      }
    
    if(force & nrow(exists) > 0)
      {
        dbGetQuery(channel, paste("drop table ",into_schema,".",into_table,sep=""))
      }
    
    if(!force & nrow(exists) >0)
      {
        existing_table <- dbGetQuery(channel,
                                     paste('select * from ',
                                           into_schema,'.',
                                           into_table,' limit 1',sep=''
                                           )
                                     )
      }
    
    if(nrow(exists) > 0 & append == TRUE)
      {
        sqlquery <- paste("INSERT INTO ",into_schema,".",into_table," (",
                             paste(names(existing_table), collapse=',', sep='') ,")\n",
                          "select ", dimensions,
                          sep = ""
                          )
      } else {
        sqlquery <- paste("select ", dimensions, "", sep = "")
      }
    
    if(!is.na(operation))
      {
        sqlquery <- paste(sqlquery, ", ", operation, "(",variable,") as ",
          ifelse(is.na(variablename), variable,
          variablename), '\n', sep = "")
      } else {
        sqlquery <- paste(sqlquery, ", ",variable," as ",
                          ifelse(is.na(variablename),variable,variablename),
                          "\n", sep="")
      }
    
    # this is when append is true but the table doesnt exist yet
    if(nrow(exists) == 0 & append == TRUE)
      {
        sqlquery <- paste(sqlquery, "into ",
                          into_schema,".",into_table,"\n", sep = ""
                          )
      }
    
    # otherwise append is false and the table just needs to be created
    if(append == FALSE)
      {
        sqlquery <- paste(sqlquery, "into ",
                          into_schema,".",into_table,"\n", sep = ""
                          )
      }
    
    sqlquery <- paste(sqlquery, "from ", from_schema,".",from_table ,"\n", sep = "")
    
    if(!is.na(where))
      {
        sqlquery <- paste(sqlquery, "where ", where, "\n", sep = "")
      }
    
    if(group_by_dimensions == TRUE)
      {
        sqlquery <- paste(sqlquery, "group by ",
                          dimensions, "\n",
                          sep = ""
                          )
      }
  #  cat(sqlquery)
    
    
    
    ## sqlquery <-  paste("select ", dimensions,
    ##                ", ",operation,"(",variables,") as ",variables,
    ##                operation, "
    ##                into ", into ,"
    ##                from ",tablename," t1
    ##                group by ",dimensions,
    ##                sep="")
    if(print) {
      cat(sqlquery)
    } else {
      dbSendQuery(channel, sqlquery)
    }
    
  }
    
#+end_src
** COMMENT sqlquery-test
#+name:sqlquery-test
#+begin_src R :session *R* :tangle no :exports none :eval no
  ################################################################
  # name:sqlquery-test
  require(ProjectTemplate)
  load.project()
  
  require(swishdbtools)
  ch <- connect2postgres(hostip='115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
  sqlquery_postgres(
      channel = ch,
      append = TRUE,
      force = FALSE,
      print = FALSE,
      dimensions = 'stnum, date',
      variable = 'gv',
      variablename = NA,
      into_schema = 'public',
      into_table = 'awapmaxave_qc2',
      from_schema = 'public',
      from_table = 'awapmaxave_qc',
      operation = NA,
      where = "date = '2013-01-02' and stnum = 70351",
      group_by_dimensions = FALSE,
      having = NA,
      grant = 'public_group'
      )
  
  dbGetQuery(ch, 'select * from awapmaxave_qc2 limit 10')
  # for dev work
  
  ##     channel = ch
  ##     dimensions = 'stnum, date'
  ##     variable = 'gv'
  ##     variablename = NA
  ##     into_schema = 'public'
  ##     into_table = 'awapmaxave_qc2'
  ##     append = TRUE
  ##     grant = 'public_group'
  ##     print = TRUE
  ##     from_schema = 'public'
  ##     from_table = 'awapmaxave_qc'
  ##     operation = NA
  ##     force = FALSE
  ##     where = "date = '2007-01-01'"
  ##     group_by_dimensions = FALSE
  ##     having = NA
  
#+end_src
** COMMENT test2
#+name:sqlquery_postgres-test2
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:sqlquery_postgres-test2



  
  
    require(ProjectTemplate)
    load.project()
  
    require(swishdbtools)
    ch <- connect2postgres(hostip='115.146.84.135', db='ewedb', user='gislibrary', p='gislibrary')
  
    variable_j <- "maxave"
    date_i <- '2012-01-01'
  #  debug(sqlquery)
    sqlquery(channel = ch,
      dimensions = paste("stnum, cast('",date_i,"' as date) as date",sep=""),
      variable = 'rt.rast, pt.the_geom',
      variablename = 'gv',
      into = 'awapmaxave_qc',
      append = FALSE,
      grant = 'public_group',
      print = FALSE,
      tablename = paste('awap_grids.',variable_j,'_',gsub('-','',date_i),' rt,\n weather_bom.combstats pt',sep=''),
      operation = "ST_Value",
      force = TRUE,
      where = "ST_Intersects(rast, the_geom)",
      group_by_dimensions = FALSE,
      having = NA)
  #  undebug(sqlquery)
  for(date_i in seq(as.Date('2012-01-21'), as.Date('2013-01-20'), 1))
    {
     date_i <- as.Date(date_i, origin = '1970-01-01')
     date_i <- as.character(date_i)
     print(date_i)
  
  #  debug(sqlquery)
    sqlquery(channel = ch,
      dimensions = paste("stnum, cast('",date_i,"' as date) as date",sep=""),
      variable = 'rt.rast, pt.the_geom',
      variablename = 'gv',
      into = 'awapmaxave_qc',
      append = TRUE,
      grant = 'public_group',
      print = FALSE,
      tablename = paste('awap_grids.',variable_j,'_',gsub('-','',date_i),' rt,\n weather_bom.combstats pt',sep=''),
      operation = "ST_Value",
      force = FALSE,
      where = "ST_Intersects(rast, the_geom)",
      group_by_dimensions = FALSE,
      having = NA)
    }
  
#+end_src
** raster_extract_by_day
*** R-raster_extract_by_day
#+name:raster_extract_by_day
#+begin_src R :session *R* :tangle R/raster_extract_by_day.r :exports none :eval no
  ################################################################
  # name:raster_extract_by_day
  raster_extract_by_day  <- function(ch = NA, startdate = NA, enddate = NA,
                                     schemaName = "weather_sla",
                                     tableName = "weather_nswsla06",
                                     pointsLayer = "abs_sla.nswsla06_points",
                                     measures = c("maxave", "minave"),
                                     zone_label = "address"
  )
  {
    
    dates <- as.character(
      seq(
        as.Date(startdate),
        as.Date(enddate), 1
      )
    )
    
    for(date_j in dates)
    {
      #date_j = dates[1]
      ################################################
      # ad hoc table "public", "tempfoobar"
      temporary_table <- swish_temptable()
      tblExists <- pgListTables(conn = ch, temporary_table$schema, 
                                temporary_table$table
                                )
      if(nrow(tblExists) >0)
      {
        dbSendQuery(conn = ch, sprintf("drop table %s", temporary_table$fullname))
      }
      #date_j <- dates[2]
      ################################################
      # the output table to append into, if exists on day one then remove
      if(date_j == dates[1])
      {
        tblExists <- pgListTables(conn = ch,schemaName,tableName)
        if(nrow(tblExists) >0)
        {
        dbSendQuery(conn = ch, sprintf("drop table  %s.%s", schemaName, tableName))
        }
      }
      
      date_i <- gsub("-","",date_j)
      #print(date_i)
      for(i in 1:length(measures))
      { # i = 1
        measure <- measures[i]
        #print(measure)
        rastername <- paste("awap_grids.", measure, "_", date_i, sep ="")
        #tableExists <- pgListTables(ch, schema="awap_grids", table=paste(measure, "_", date_i, sep =""))
        #if(nrow(tableExists) > 0)
        #{
        sql <- postgis_raster_extract(conn = ch, x=rastername, 
                                      y=pointsLayer, 
                                      zone_label = zone_label, 
                                      value_label = "value"
                                      )
        sql <- gsub("FROM", 
                    sprintf("INTO %s.%s\nFROM", temporary_table$schema, 
                            temporary_table$table)
                    ,
                    sql)
        #cat(sql)  
        
        dbSendQuery(conn = ch, statement = sql) 
        
        tblExists <- pgListTables(conn = ch, schemaName, tableName)
        if(nrow(tblExists) == 0)
        {
          sql <- sql_subset_into(conn = ch, x=temporary_table$fullname, 
                                 into_schema=schemaName,
                                 into_table=tableName,eval=F, drop=F
          )
          # cat(sql)
          dbSendQuery(conn = ch, sql)      
        } else {
          sql <- sql_subset(conn = ch, x=temporary_table$fullname, eval=F)
          sql <- paste("INSERT INTO ",schemaName,".",tableName," (
            ", zone_label, ", raster_layer, value)
            ",sql,sep ="")
          #cat(sql)
          dbSendQuery(conn = ch, sql)
        }
        dbSendQuery(conn = ch, sprintf("drop table %s", temporary_table$fullname))
        #}
      }
    }
  }
  
  
  
  
  
  
    
    
#+end_src
*** test-raster_extract_by_day
#+name:raster_extract_by_day
#+begin_src R :session *R* :tangle tests/test-raster_extract_by_day.r :exports none :eval no
  ################################################################
  # name:raster_extract_by_day
  require(swishdbtools)
  require(awaptools)
  startdate <- "2013-04-01" #StartDate
  enddate <- "2013-04-02" #EndDate
  
  ch<-connect2postgres2("ewedb")
  
  
  # get locations
  stn  <- sql_subset(ch, "weather_bom.combstats", eval = T)
  head(stn)  
  
  # clean
  names(stn) <- gsub("lon", "long", names(stn))
  names(stn) <- gsub("gid", "gid2", names(stn))
  nrow(stn)
  
  # sample
  percentSample <- 0.01
  sampled  <- sample(stn$stnum, percentSample * nrow(stn))
  length(sampled)
  locations  <- stn[which(stn$stnum %in% sampled),]
  head(locations)
  
  # send to postgis
  tempTableName <- swish_temptable()
  sch <- tempTableName$schema
  tbl <- tempTableName$table
  
  tempTableName <- tempTableName$fullname
  
  exists <- pgListTables(ch, sch, tbl)
  if(nrow(exists) > 0){
    dbSendQuery(ch, 
                sprintf("drop table %s.%s", sch, tbl)
    )
  }
  dbWriteTable(ch, tbl, locations, row.names = F)
  tested <- sql_subset(ch, tempTableName, eval = T)
  # head(tested)
  
  tempTableName
  
  # points2geom
  
  sql <- points2geom(
    schema=sch,
    tablename=tbl,
    col_lat= "lat",col_long="long", srid="4283"
  )
  # cat(sql)
  dbSendQuery(ch, sql)
  tbl
  
  # raster extract
  raster_extract_by_day(ch, startdate, enddate,
                                     schemaName = sch
                        ,
                                     tableName = "output_one"
                        ,
                                     pointsLayer = tempTableName
                        ,
                                     measures = c("maxave", "minave")
                        ,
                        zone_label = "stnum"
  )
  
  schemaTableName <- paste(sep=".", sch, "output_one")
  
  # get result and reformat
  require(swishdbtools)
  require(awaptools)
  require(reshape)
  data <- reformat_awap_data(
    tableName = schemaTableName,
    zone_label = "stnum"
  )
  
  tempFileName <- tempfile("foo", tmpdir = Sys.getenv("TEMP"), fileext = "")
  write.dta(data, tempFileName)
  tempFileName
  
  
  ################################################################
  # name: tidy up
  require(swishdbtools)
  ch<-connect2postgres2("ewedb")
  sch <- swish_temptable("ewedb")
  sch <- sch$schema
  tbls <- pgListTables(ch, sch, table="foo", match = FALSE)
  tbls
  for(tab in tbls[,1])
  {
    #tab <- tbls[1,1]
    dbSendQuery(ch, 
                sprintf("drop table %s.\"%s\"", sch, tab)
    )
  }
  
#+end_src
*** man-raster_extract_by_day
#+name:raster_extract_by_day
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:raster_extract_by_day

#+end_src

** reformat_awap_data
*** R-reformat_awap_data
#+name:reformat_awap_data
#+begin_src R :session *R* :tangle R/reformat_awap_data.r :exports none :eval no
################################################################
# name:reformat_awap_data
reformat_awap_data  <- function(
  tableName = "weather_sla.weather_nswsla06",
  zone_label = "address"
)
{
  dat <- sql_subset(ch, tableName, eval = T)
  dat$date <- matrix(unlist(strsplit(dat$raster_layer, "_")), ncol = 3, byrow=TRUE)[,3]
  dat$date <- paste(substr(dat$date,1,4), substr(dat$date,5,6), substr(dat$date,7,8), sep = "-")
  dat$measure <- matrix(unlist(strsplit(dat$raster_layer, "_")), ncol = 3, byrow=TRUE)[,2]
  dat$measure <- gsub("grids.","",dat$measure)
  
  dat <- arrange(dat,  date, measure)
  #  dat <- as.data.frame(cast(dat, address + date ~ measure, value = "value",
  #                            fun.aggregate= "mean")
  #                       )
  dat <- eval(
    parse(
      text=sprintf(
        "as.data.frame(cast(dat, %s + date ~ measure, value = 'value',
                            fun.aggregate= 'mean')
                       )", zone_label
      )
    )
  )
  
  dat$date <- as.Date(dat$date)
  return(dat)
}
#+end_src
*** test-reformat_awap_data
#+name:reformat_awap_data
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:reformat_awap_data

#+end_src
*** man-reformat_awap_data
#+name:reformat_awap_data
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:reformat_awap_data

#+end_src

** load_monthly
*** R-load_monthly
#+name:load_monthly
#+begin_src R :session *R* :tangle R/load_monthly.r :exports none :eval no
  ################################################################
  # name:load-monthly
  # workdir <- getwd()
  # outdir <- outdir
  # setwd(outdir)
  #start_date <- as.POSIXlt(start_date)
  #require(devtools)
  #install_github("awaptools", "swish-climate-impact-assessment")
  load_monthly <- function(start_date, end_date)
    {
    start_date <- as.POSIXlt(start_date)
    end_date <- as.POSIXlt(end_date)
    variableslist <- variableslist()
    variableslist
    vname <- variableslist[1,1]
    measure_i <- variableslist[1,2]
    dateslist <- as.character(seq(start_date, end_date, by = "month"))
    for(date_i in dateslist)
      {
    #    date_i <- dateslist[1]
        flist <- dir(pattern = measure_i)
        fileExists <- grep(paste(measure_i, gsub("-", "", date_i), sep = "_"), flist)
        if(length(fileExists) > 0)
          {
            next
          }
  
        sdate <- as.POSIXct(date_i)
        if(as.numeric(format(sdate, "%m")) < 12)
          {
                     edate <- as.POSIXct(paste
                                (format(sdate, "%Y"),
                                 as.numeric(format(sdate, "%m")) + 1, 1, sep = "-"
                                 )
                                )
           } else {
                     edate <- as.POSIXct(paste
                                (as.numeric(format(sdate, "%Y")) +1,
                                 1, 1, sep = "-"
                                 )
                                )
           }
        get_data_range(
                       variable = vname,
                       measure = measure_i,
                       timestep = "monthly",
                       startdate = sdate,
                       enddate = edate
                   )
      }
  }
  
#+end_src
*** test-load_monthly
#+name:load_monthly
#+begin_src R :session *R* :tangle tests/test-load_monthly.r :exports none :eval no
################################################################
# name:load_monthly

#+end_src
*** man-load_monthly
#+name:load_monthly
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:load_monthly

#+end_src

** unzip_monthly
*** R-unzip_monthly

#+name:unzip
#+begin_src R :session *R* :tangle R/unzip_monthly.r :exports none :eval no
  ################################################################
  # name:unzip
  ## load(".RData")
  ## setwd(outdir)
  ## require(devtools)
  ## install_github("awaptools", "swish-climate-impact-assessment")
  ## require(awaptools)
  ## require(swishdbtools)
  unzip_monthly <- function(filename, aggregation_factor = 1)
    {
      if(file.exists(filename))
        {
          fname <- filename
        } else {
          stop("file doesn't exist")
        }
    require(raster)
    require(swishdbtools)
    os <- LinuxOperatingSystem()
  
  
  
     if(os)
       {
         uncompress_linux(filename = fname)
       } else {
         Decompress7Zip(zipFileName= fname, outputDirectory=getwd(), TRUE)
       }
  
       #raster_aggregate(filename = gsub('.Z$','',fname),
       #  aggregationfactor = aggregation_factor, delete = TRUE)
       
  
    }
  
#+end_src

*** test-unzip_monthly
#+name:unzip_monthly
#+begin_src R :session *R* :tangle tests/test-unzip_monthly.r :exports none :eval no
################################################################
# name:unzip_monthly

#+end_src
*** man-unzip_monthly
#+name:unzip_monthly
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:unzip_monthly

#+end_src

